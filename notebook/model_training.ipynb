{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11bd20a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c8be27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:\\\\sentiment_analysis_project\\\\notebook\\\\processed_tweets.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c35cb8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>115</td>\n",
       "      <td>switchfoot http twitpic com y zl awww s bummer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>111</td>\n",
       "      <td>upset t update facebook texte cry result schoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>89</td>\n",
       "      <td>kenichan dive time ball manage save rest bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>47</td>\n",
       "      <td>body feel itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>111</td>\n",
       "      <td>nationwideclass s behave m mad t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \\\n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...   \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...   \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire    \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "   text_length                                              lemma  \n",
       "0          115  switchfoot http twitpic com y zl awww s bummer...  \n",
       "1          111  upset t update facebook texte cry result schoo...  \n",
       "2           89     kenichan dive time ball manage save rest bound  \n",
       "3           47                          body feel itchy like fire  \n",
       "4          111                   nationwideclass s behave m mad t  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4387a267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'ids', 'date', 'flag', 'user', 'text', 'text_length',\n",
       "       'lemma'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99c96ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          switchfoot http twitpic com y zl awww s bummer...\n",
       "1          upset t update facebook texte cry result schoo...\n",
       "2             kenichan dive time ball manage save rest bound\n",
       "3                                  body feel itchy like fire\n",
       "4                           nationwideclass s behave m mad t\n",
       "                                 ...                        \n",
       "1599995                        wake have school good feeling\n",
       "1599996    thewdb com cool hear old walt interview http b...\n",
       "1599997                       ready mojo makeover ask detail\n",
       "1599998    happy th birthday boo alll time tupac amaru sh...\n",
       "1599999    happy charitytuesday thenspcc sparkscharity sp...\n",
       "Name: lemma, Length: 1600000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28603cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "          ..\n",
       "1599995    1\n",
       "1599996    1\n",
       "1599997    1\n",
       "1599998    1\n",
       "1599999    1\n",
       "Name: target, Length: 1600000, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d32f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Clean using pandas\n",
    "#    (drop missing labels or missing/empty texts)\n",
    "clean_mask = (\n",
    "    df['target'].notna()\n",
    "    & df['lemma'].notna()\n",
    "    & (df['lemma'].astype(str).str.strip() != '')\n",
    ")\n",
    "df_clean = df.loc[clean_mask, ['lemma', 'target']]\n",
    "\n",
    "# 2) Convert to NumPy arrays\n",
    "X = df_clean['lemma'].to_numpy()   # dtype=object (strings)\n",
    "y = df_clean['target'].to_numpy()  # numeric/str labels\n",
    "\n",
    "# 3) Split with stratification on the NumPy y\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=24\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e059bf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes -> train: 1,120,000 | val: 160,000 | test: 320,000\n",
      "Feature shapes -> train: (1120000, 230000) val: (160000, 230000) test: (320000, 230000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training C=1.5:  12%|█▎        | 1/8 [01:06<07:44, 66.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iter   50 -> val_acc: 0.7885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training C=1.5:  25%|██▌       | 2/8 [02:13<06:39, 66.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iter  100 -> val_acc: 0.7884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training C=1.5:  38%|███▊      | 3/8 [03:14<05:21, 64.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iter  150 -> val_acc: 0.7884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training C=1.5:  38%|███▊      | 3/8 [04:37<07:42, 92.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iter  200 -> val_acc: 0.7884\n",
      "  Early stop on validation.\n",
      "[C=1.5] best val acc: 0.7885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training C=3.0:  12%|█▎        | 1/8 [01:22<09:39, 82.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iter   50 -> val_acc: 0.7852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training C=3.0:  25%|██▌       | 2/8 [02:50<08:33, 85.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iter  100 -> val_acc: 0.7851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training C=3.0:  38%|███▊      | 3/8 [04:04<06:42, 80.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iter  150 -> val_acc: 0.7850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training C=3.0:  38%|███▊      | 3/8 [05:27<09:06, 109.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iter  200 -> val_acc: 0.7850\n",
      "  Early stop on validation.\n",
      "[C=3.0] best val acc: 0.7852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training C=6.0:  12%|█▎        | 1/8 [01:49<12:49, 109.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iter   50 -> val_acc: 0.7782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training C=6.0:  25%|██▌       | 2/8 [03:11<09:18, 93.14s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iter  100 -> val_acc: 0.7778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training C=6.0:  38%|███▊      | 3/8 [04:23<06:57, 83.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iter  150 -> val_acc: 0.7779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training C=6.0:  38%|███▊      | 3/8 [05:35<09:18, 111.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iter  200 -> val_acc: 0.7777\n",
      "  Early stop on validation.\n",
      "[C=6.0] best val acc: 0.7782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training C=10.0:  12%|█▎        | 1/8 [01:49<12:43, 109.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iter   50 -> val_acc: 0.7774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training C=10.0:  25%|██▌       | 2/8 [03:08<09:08, 91.43s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iter  100 -> val_acc: 0.7772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training C=10.0:  38%|███▊      | 3/8 [04:35<07:26, 89.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iter  150 -> val_acc: 0.7772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training C=10.0:  38%|███▊      | 3/8 [06:04<10:07, 121.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iter  200 -> val_acc: 0.7773\n",
      "  Early stop on validation.\n",
      "[C=10.0] best val acc: 0.7774\n",
      "Selected C=1.5 with val acc=0.7885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8385\n",
      "Val   acc: 0.7885\n",
      "Test  acc: 0.7886\n",
      "\n",
      "Test classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7984    0.7721    0.7850    160000\n",
      "           1     0.7794    0.8050    0.7920    160000\n",
      "\n",
      "    accuracy                         0.7886    320000\n",
      "   macro avg     0.7889    0.7886    0.7885    320000\n",
      "weighted avg     0.7889    0.7886    0.7885    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- config (tweak these based on your RAM/time) ---\n",
    "RANDOM_STATE = 24\n",
    "WORD_MAX_FEATURES = 150_000\n",
    "CHAR_MAX_FEATURES = 80_000\n",
    "WORD_NGRAMS = (1, 2)     # try (1,3) for more capacity (slower)\n",
    "CHAR_NGRAMS = (3, 5)\n",
    "MIN_DF = 5               # lower (e.g., 3) => more features (risk overfit/slower)\n",
    "MAX_DF = 0.95\n",
    "TOTAL_ITERS = 400        # total saga iterations per C\n",
    "STEP_ITERS = 50          # iterations per chunk (granularity of progress)\n",
    "TOL = 2e-3               # looser tol speeds convergence; tighten if needed\n",
    "C_GRID = [1.5, 3.0, 6.0, 10.0]  # capacity search; add 15.0, 20.0 if underfitting\n",
    "PATIENCE = 3             # early-stop if val acc doesn't improve this many chunks\n",
    "\n",
    "# ================= CODE START =================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 0) Input: df with columns 'lemma' (text) and 'target' (labels)\n",
    "# Make sure your df exists in memory before running this cell.\n",
    "\n",
    "# 1) Clean text/labels\n",
    "text = df['lemma'].astype(str)\n",
    "labels = df['target']\n",
    "\n",
    "mask = labels.notna() & text.notna() & (text.str.strip() != '')\n",
    "text = text[mask]\n",
    "labels = labels[mask]\n",
    "\n",
    "# 2) Train/val/test split (stratified)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    text, labels, test_size=0.20, stratify=labels, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# build a small validation set from the training portion\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.125,  # 0.8*0.125=0.10 overall val\n",
    "    stratify=y_train_full, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Sizes -> train: {len(X_train):,} | val: {len(X_val):,} | test: {len(X_test):,}\")\n",
    "\n",
    "# 3) Vectorize once (fit on TRAIN only)\n",
    "word_vec = TfidfVectorizer(\n",
    "    analyzer=\"word\",\n",
    "    ngram_range=WORD_NGRAMS,\n",
    "    min_df=MIN_DF,\n",
    "    max_df=MAX_DF,\n",
    "    sublinear_tf=True,\n",
    "    max_features=WORD_MAX_FEATURES,\n",
    "    dtype=np.float32\n",
    ")\n",
    "char_vec = TfidfVectorizer(\n",
    "    analyzer=\"char\",\n",
    "    ngram_range=CHAR_NGRAMS,\n",
    "    min_df=MIN_DF,\n",
    "    sublinear_tf=True,\n",
    "    max_features=CHAR_MAX_FEATURES,\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "Xw_tr = word_vec.fit_transform(X_train)\n",
    "Xc_tr = char_vec.fit_transform(X_train)\n",
    "Xw_val = word_vec.transform(X_val)\n",
    "Xc_val = char_vec.transform(X_val)\n",
    "Xw_te = word_vec.transform(X_test)\n",
    "Xc_te = char_vec.transform(X_test)\n",
    "\n",
    "Xtr  = hstack([Xw_tr,  Xc_tr],  format=\"csr\", dtype=np.float32)\n",
    "Xval = hstack([Xw_val, Xc_val], format=\"csr\", dtype=np.float32)\n",
    "Xte  = hstack([Xw_te,  Xc_te],  format=\"csr\", dtype=np.float32)\n",
    "\n",
    "print(\"Feature shapes ->\",\n",
    "      f\"train: {Xtr.shape}\", f\"val: {Xval.shape}\", f\"test: {Xte.shape}\")\n",
    "\n",
    "# 4) Training helper: chunked saga with progress + early stopping\n",
    "def train_logreg_with_progress(Xtr, ytr, Xval, yval, C, total_iters, step_iters, tol, patience):\n",
    "    clf = LogisticRegression(\n",
    "        solver=\"saga\",\n",
    "        penalty=\"l2\",\n",
    "        C=C,\n",
    "        warm_start=True,\n",
    "        max_iter=step_iters,\n",
    "        tol=tol,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    best_val = -np.inf\n",
    "    best_state = None\n",
    "    bad_streak = 0\n",
    "\n",
    "    chunks = range(0, total_iters, step_iters)\n",
    "    for done in tqdm(chunks, desc=f\"Training C={C}\"):\n",
    "        clf.max_iter = step_iters\n",
    "        clf.fit(Xtr, ytr)  # continues from previous state due to warm_start\n",
    "\n",
    "        # Live metrics\n",
    "        yval_pred = clf.predict(Xval)\n",
    "        val_acc = accuracy_score(yval, yval_pred)\n",
    "        print(f\"  iter {done+step_iters:4d} -> val_acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val + 1e-4:\n",
    "            best_val = val_acc\n",
    "            # snapshot coefficients (copy to avoid mutation on next fit)\n",
    "            best_state = {\n",
    "                \"coef_\": clf.coef_.copy(),\n",
    "                \"intercept_\": clf.intercept_.copy(),\n",
    "                \"classes_\": clf.classes_.copy()\n",
    "            }\n",
    "            bad_streak = 0\n",
    "        else:\n",
    "            bad_streak += 1\n",
    "            if bad_streak >= patience:\n",
    "                print(\"  Early stop on validation.\")\n",
    "                break\n",
    "\n",
    "    # restore best weights\n",
    "    if best_state is not None:\n",
    "        clf.coef_ = best_state[\"coef_\"]\n",
    "        clf.intercept_ = best_state[\"intercept_\"]\n",
    "        clf.classes_ = best_state[\"classes_\"]\n",
    "\n",
    "    return clf, best_val\n",
    "\n",
    "# 5) Small search over C (capacity) with validation\n",
    "best_clf = None\n",
    "best_val_acc = -np.inf\n",
    "best_C = None\n",
    "\n",
    "for C in C_GRID:\n",
    "    clf, val_acc = train_logreg_with_progress(\n",
    "        Xtr, y_train.values, Xval, y_val.values,\n",
    "        C=C, total_iters=TOTAL_ITERS, step_iters=STEP_ITERS,\n",
    "        tol=TOL, patience=PATIENCE\n",
    "    )\n",
    "    print(f\"[C={C}] best val acc: {val_acc:.4f}\")\n",
    "    # choose simpler C on ties\n",
    "    if (val_acc > best_val_acc + 1e-4) or (abs(val_acc - best_val_acc) <= 1e-4 and (best_C is None or C < best_C)):\n",
    "        best_val_acc = val_acc\n",
    "        best_clf = clf\n",
    "        best_C = C\n",
    "\n",
    "print(f\"Selected C={best_C} with val acc={best_val_acc:.4f}\")\n",
    "\n",
    "# 6) Evaluate on held-out TEST\n",
    "ytr_pred  = best_clf.predict(Xtr)\n",
    "yval_pred = best_clf.predict(Xval)\n",
    "yte_pred  = best_clf.predict(Xte)\n",
    "\n",
    "print(f\"Train acc: {accuracy_score(y_train, ytr_pred):.4f}\")\n",
    "print(f\"Val   acc: {accuracy_score(y_val,   yval_pred):.4f}\")\n",
    "print(f\"Test  acc: {accuracy_score(y_test,  yte_pred):.4f}\")\n",
    "\n",
    "print(\"\\nTest classification report:\")\n",
    "print(classification_report(y_test, yte_pred, digits=4))\n",
    "# ================= CODE END =================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c08e8c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to text_lr_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save all components together\n",
    "joblib.dump(\n",
    "    {\n",
    "        \"word_vec\": word_vec,   # fitted word-level TfidfVectorizer\n",
    "        \"char_vec\": char_vec,   # fitted char-level TfidfVectorizer\n",
    "        \"model\": best_clf       # fitted LogisticRegression\n",
    "    },\n",
    "    \"text_lr_model.joblib\",\n",
    "    compress=3\n",
    ")\n",
    "\n",
    "print(\"Model saved to text_lr_model.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
